{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vZVJziVF4LT",
        "outputId": "9dbd7017-6709-4f3f-c9d3-f15d3d61d941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Generating improved dataset with realistic patterns...\n",
            "âœ… Generated 5100 transactions\n",
            "   - Normal: 5000 (98.0%)\n",
            "   - Fraud: 100 (2.0%)\n",
            "\n",
            "ğŸ“Š Fraud Amount Range: RM 6.75 - RM 4897.50\n",
            "ğŸ“Š Normal Amount Range: RM 2.00 - RM 199.87\n",
            "\n",
            "ğŸ’¾ Saved to 'amanpay_transactions.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "NUM_NORMAL = 5000\n",
        "NUM_FRAUD = 100\n",
        "OUTPUT_FILE = \"amanpay_transactions_improved.csv\"\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def generate_normal_transaction():\n",
        "    \"\"\"Simulates realistic student spending in Malaysia\"\"\"\n",
        "    categories = ['Food', 'Transport', 'Telco', 'Grocery', 'Entertainment', 'Education']\n",
        "\n",
        "    # More realistic spending distribution\n",
        "    category = random.choice(categories)\n",
        "\n",
        "    # Different spending patterns per category\n",
        "    if category == 'Food':\n",
        "        amount = round(np.random.gamma(3, 5), 2)  # RM 5-30 typically\n",
        "    elif category == 'Transport':\n",
        "        amount = round(np.random.gamma(2, 3), 2)  # RM 3-15\n",
        "    elif category == 'Education':\n",
        "        amount = round(np.random.uniform(50, 200), 2)  # Books, materials\n",
        "    else:\n",
        "        amount = round(np.random.gamma(3, 7), 2)\n",
        "\n",
        "    amount = max(2.0, min(amount, 500))  # Cap at RM 500 for normal\n",
        "\n",
        "    # Realistic hours - students are active during day\n",
        "    # Peak times: lunch (12-2), dinner (6-8), late night (10-12)\n",
        "    hour_weights = [1, 1, 1, 1, 1, 2, 3, 5, 7, 8, 6, 8, 10, 9, 7, 6, 5, 7, 9, 8, 6, 5, 4, 3]\n",
        "    hour = random.choices(range(24), weights=hour_weights, k=1)[0]\n",
        "\n",
        "    # Local coordinates (Kampar, KL, Penang areas)\n",
        "    locations = [\n",
        "        (4.3352, 101.1529),  # Kampar\n",
        "        (3.1390, 101.6869),  # KL\n",
        "        (5.4164, 100.3327),  # Penang\n",
        "    ]\n",
        "    base_lat, base_lon = random.choice(locations)\n",
        "    lat = round(base_lat + random.uniform(-0.1, 0.1), 4)\n",
        "    lon = round(base_lon + random.uniform(-0.1, 0.1), 4)\n",
        "\n",
        "    return {\n",
        "        \"amount\": amount,\n",
        "        \"hour\": hour,\n",
        "        \"category\": category,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"is_fraud\": 0\n",
        "    }\n",
        "\n",
        "def generate_fraud_transaction():\n",
        "    \"\"\"Simulates various types of fraud with realistic patterns\"\"\"\n",
        "    fraud_types = ['BIG_DRAIN', 'PHISHING', 'SMALL_REPEATED', 'OVERSEAS', 'ODD_HOURS']\n",
        "    fraud_type = random.choice(fraud_types)\n",
        "\n",
        "    if fraud_type == 'BIG_DRAIN':\n",
        "        # Large unauthorized transfer\n",
        "        amount = round(random.uniform(1500, 5000), 2)\n",
        "        hour = random.randint(0, 6)  # Late night/early morning\n",
        "        category = \"Transfer\"\n",
        "        # Could be local or overseas\n",
        "        if random.random() < 0.5:\n",
        "            lat = round(random.uniform(3.0, 5.0), 4)\n",
        "            lon = round(random.uniform(101.0, 102.0), 4)\n",
        "        else:\n",
        "            lat = round(random.uniform(10.0, 50.0), 4)\n",
        "            lon = round(random.uniform(110.0, 130.0), 4)\n",
        "\n",
        "    elif fraud_type == 'PHISHING':\n",
        "        # Fake website/app - specific amounts\n",
        "        amount = random.choice([199.00, 299.00, 99.00, 499.00])\n",
        "        hour = random.randint(0, 23)  # Can happen anytime\n",
        "        category = random.choice([\"Transfer\", \"Entertainment\", \"Shopping\"])\n",
        "        # Overseas locations\n",
        "        lat = round(random.uniform(15.0, 40.0), 4)\n",
        "        lon = round(random.uniform(100.0, 125.0), 4)\n",
        "\n",
        "    elif fraud_type == 'SMALL_REPEATED':\n",
        "        # Testing stolen card with small amounts\n",
        "        amount = round(random.uniform(5, 50), 2)\n",
        "        hour = random.randint(0, 5)  # Odd hours\n",
        "        category = random.choice([\"Food\", \"Grocery\", \"Entertainment\"])\n",
        "        # Foreign location\n",
        "        lat = round(random.uniform(20.0, 50.0), 4)\n",
        "        lon = round(random.uniform(105.0, 130.0), 4)\n",
        "\n",
        "    elif fraud_type == 'OVERSEAS':\n",
        "        # Legitimate-looking amount but weird location\n",
        "        amount = round(random.uniform(100, 800), 2)\n",
        "        hour = random.randint(8, 23)  # Normal hours\n",
        "        category = random.choice([\"Shopping\", \"Entertainment\", \"Transfer\"])\n",
        "        # Definitely overseas (China, Nigeria, Eastern Europe)\n",
        "        regions = [\n",
        "            (35.0, 105.0, 45.0, 115.0),  # China\n",
        "            (8.0, 3.0, 12.0, 8.0),       # Nigeria\n",
        "            (45.0, 20.0, 55.0, 40.0),    # Eastern Europe\n",
        "        ]\n",
        "        region = random.choice(regions)\n",
        "        lat = round(random.uniform(region[0], region[2]), 4)\n",
        "        lon = round(random.uniform(region[1], region[3]), 4)\n",
        "\n",
        "    else:  # ODD_HOURS\n",
        "        # Normal amount but suspicious timing\n",
        "        amount = round(random.uniform(200, 1000), 2)\n",
        "        hour = random.randint(1, 4)  # 1-4 AM\n",
        "        category = \"Transfer\"\n",
        "        # Could be local\n",
        "        lat = round(random.uniform(3.0, 5.5), 4)\n",
        "        lon = round(random.uniform(100.5, 102.0), 4)\n",
        "\n",
        "    return {\n",
        "        \"amount\": amount,\n",
        "        \"hour\": hour,\n",
        "        \"category\": category,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"is_fraud\": 1\n",
        "    }\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "print(\"ğŸ”„ Generating improved dataset with realistic patterns...\")\n",
        "\n",
        "data = []\n",
        "\n",
        "# Generate normal transactions\n",
        "for _ in range(NUM_NORMAL):\n",
        "    data.append(generate_normal_transaction())\n",
        "\n",
        "# Generate fraud transactions\n",
        "for _ in range(NUM_FRAUD):\n",
        "    data.append(generate_fraud_transaction())\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Shuffle the data\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Show statistics\n",
        "print(f\"âœ… Generated {len(df)} transactions\")\n",
        "print(f\"   - Normal: {len(df[df['is_fraud']==0])} ({len(df[df['is_fraud']==0])/len(df)*100:.1f}%)\")\n",
        "print(f\"   - Fraud: {len(df[df['is_fraud']==1])} ({len(df[df['is_fraud']==1])/len(df)*100:.1f}%)\")\n",
        "print(f\"\\nğŸ“Š Fraud Amount Range: RM {df[df['is_fraud']==1]['amount'].min():.2f} - RM {df[df['is_fraud']==1]['amount'].max():.2f}\")\n",
        "print(f\"ğŸ“Š Normal Amount Range: RM {df[df['is_fraud']==0]['amount'].min():.2f} - RM {df[df['is_fraud']==0]['amount'].max():.2f}\")\n",
        "print(f\"\\nğŸ’¾ Saved to '{OUTPUT_FILE}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "baeZyia0GEhr",
        "outputId": "49d8e5d5-1462-4879-eef7-ccb7debcd940"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5100,\n  \"fields\": [\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 225.94311023336687,\n        \"min\": 2.0,\n        \"max\": 4958.37,\n        \"num_unique_values\": 3256,\n        \"samples\": [\n          50.09,\n          4.02,\n          53.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          17,\n          11,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Grocery\",\n          \"Entertainment\",\n          \"Telco\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.652602417188044,\n        \"min\": 3.039,\n        \"max\": 51.927,\n        \"num_unique_values\": 3544,\n        \"samples\": [\n          5.3729,\n          5.3526,\n          5.3548\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.346658661504578,\n        \"min\": 4.5902,\n        \"max\": 129.9699,\n        \"num_unique_values\": 3510,\n        \"samples\": [\n          100.3955,\n          100.3954,\n          101.6496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_fraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-37d65208-ff24-4806-867a-92240594b09c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>hour</th>\n",
              "      <th>category</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>is_fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.09</td>\n",
              "      <td>8</td>\n",
              "      <td>Telco</td>\n",
              "      <td>5.3372</td>\n",
              "      <td>100.2795</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.76</td>\n",
              "      <td>12</td>\n",
              "      <td>Telco</td>\n",
              "      <td>5.4146</td>\n",
              "      <td>100.3291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.39</td>\n",
              "      <td>13</td>\n",
              "      <td>Grocery</td>\n",
              "      <td>4.3639</td>\n",
              "      <td>101.1646</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.63</td>\n",
              "      <td>8</td>\n",
              "      <td>Telco</td>\n",
              "      <td>3.1023</td>\n",
              "      <td>101.7447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199.89</td>\n",
              "      <td>8</td>\n",
              "      <td>Education</td>\n",
              "      <td>4.2475</td>\n",
              "      <td>101.1211</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>7.02</td>\n",
              "      <td>8</td>\n",
              "      <td>Food</td>\n",
              "      <td>3.1832</td>\n",
              "      <td>101.6926</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>128.87</td>\n",
              "      <td>17</td>\n",
              "      <td>Education</td>\n",
              "      <td>5.3395</td>\n",
              "      <td>100.4033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>3.83</td>\n",
              "      <td>9</td>\n",
              "      <td>Transport</td>\n",
              "      <td>3.0875</td>\n",
              "      <td>101.6834</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>5.41</td>\n",
              "      <td>12</td>\n",
              "      <td>Telco</td>\n",
              "      <td>4.3908</td>\n",
              "      <td>101.1444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>3.86</td>\n",
              "      <td>21</td>\n",
              "      <td>Transport</td>\n",
              "      <td>3.0480</td>\n",
              "      <td>101.6387</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d65208-ff24-4806-867a-92240594b09c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37d65208-ff24-4806-867a-92240594b09c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37d65208-ff24-4806-867a-92240594b09c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8eae210a-517a-41e2-ba30-3a885bb65914\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8eae210a-517a-41e2-ba30-3a885bb65914 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      amount  hour   category     lat       lon  is_fraud\n",
              "0      10.09     8      Telco  5.3372  100.2795         0\n",
              "1      32.76    12      Telco  5.4146  100.3291         0\n",
              "2      10.39    13    Grocery  4.3639  101.1646         0\n",
              "3      15.63     8      Telco  3.1023  101.7447         0\n",
              "4     199.89     8  Education  4.2475  101.1211         0\n",
              "...      ...   ...        ...     ...       ...       ...\n",
              "5095    7.02     8       Food  3.1832  101.6926         0\n",
              "5096  128.87    17  Education  5.3395  100.4033         0\n",
              "5097    3.83     9  Transport  3.0875  101.6834         0\n",
              "5098    5.41    12      Telco  4.3908  101.1444         0\n",
              "5099    3.86    21  Transport  3.0480  101.6387         0\n",
              "\n",
              "[5100 rows x 6 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad-OkheGHfF",
        "outputId": "949c7a5b-9bdf-4ea8-831e-0506d3110eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§¹ Starting Data Cleaning Process...\n",
            "   -> Loaded 5100 rows.\n",
            "   -> No missing values found. (Good!)\n",
            "   -> No duplicates found.\n",
            "------------------------------------------------\n",
            "Data Cleaning Complete!\n",
            "   -> Saved cleaned data to: 'amanpay_cleaned.csv'\n",
            "------------------------------------------------\n",
            "\n",
            "Data Preview (First 5 rows):\n",
            "   amount  hour   category     lat       lon  is_fraud\n",
            "0    5.79    10  Transport  3.1427  101.6293         0\n",
            "1   14.77    14    Grocery  5.3434  100.3573         0\n",
            "2   11.81     4    Grocery  4.4134  101.2468         0\n",
            "3   12.77    19       Food  5.4425  100.3840         0\n",
            "4    5.79    12       Food  3.2247  101.6697         0\n",
            "\n",
            "Statistics:\n",
            "            amount         hour          lat          lon     is_fraud\n",
            "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000\n",
            "mean     49.864124    13.341176     4.650604   100.992859     0.019608\n",
            "std     185.551196     5.318164     3.548747     4.739280     0.138662\n",
            "min       2.000000     0.000000     3.000400     3.108000     0.000000\n",
            "25%       9.370000     9.000000     3.189975   100.385575     0.000000\n",
            "50%      17.795000    13.000000     4.336450   101.159850     0.000000\n",
            "75%      34.115000    18.000000     5.369500   101.641850     0.000000\n",
            "max    4977.210000    23.000000    54.150500   129.937900     1.000000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INPUT_FILE = \"amanpay_transactions.csv\"\n",
        "OUTPUT_FILE = \"amanpay_cleaned.csv\"\n",
        "\n",
        "def clean_data():\n",
        "    print(\"ğŸ§¹ Starting Data Cleaning Process...\")\n",
        "\n",
        "    # 1. Load the Data\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_FILE)\n",
        "        print(f\"   -> Loaded {len(df)} rows.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ Error: generate_data.py hasn't been run yet!\")\n",
        "        return\n",
        "\n",
        "    # 2. Check for Missing Values (and remove them)\n",
        "    if df.isnull().sum().sum() > 0:\n",
        "        print(f\"   -> Found missing values. Removing...\")\n",
        "        df = df.dropna()\n",
        "    else:\n",
        "        print(\"   -> No missing values found. (Good!)\")\n",
        "\n",
        "    # 3. Remove Duplicates\n",
        "    # In real banking, duplicates might happen due to system glitches\n",
        "    initial_count = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    final_count = len(df)\n",
        "\n",
        "    if initial_count > final_count:\n",
        "        print(f\"   -> Removed {initial_count - final_count} duplicate rows.\")\n",
        "    else:\n",
        "        print(\"   -> No duplicates found.\")\n",
        "\n",
        "    # 4. Data Type Conversion (Optimization)\n",
        "    # Ensure 'amount' is a number (float)\n",
        "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
        "\n",
        "    # 5. Save the Cleaned Data\n",
        "    df.to_csv(OUTPUT_FILE, index=False)\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(f\"Data Cleaning Complete!\")\n",
        "    print(f\"   -> Saved cleaned data to: '{OUTPUT_FILE}'\")\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "    # Show a quick summary for the User\n",
        "    print(\"\\nData Preview (First 5 rows):\")\n",
        "    print(df.head())\n",
        "    print(\"\\nStatistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clean_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8cOLnn3GOvj",
        "outputId": "d92a1f4d-40ce-41b9-c832-ce3c7f33740b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Training on 4000 normal transactions...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.6220 - val_loss: 0.5114\n",
            "Epoch 2/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4712 - val_loss: 0.3860\n",
            "Epoch 3/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3706 - val_loss: 0.3570\n",
            "Epoch 4/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3506 - val_loss: 0.3417\n",
            "Epoch 5/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3314 - val_loss: 0.3175\n",
            "Epoch 6/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3126 - val_loss: 0.2827\n",
            "Epoch 7/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2759 - val_loss: 0.2700\n",
            "Epoch 8/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2675 - val_loss: 0.2672\n",
            "Epoch 9/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2644 - val_loss: 0.2666\n",
            "Epoch 10/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2637 - val_loss: 0.2657\n",
            "Epoch 11/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2629 - val_loss: 0.2651\n",
            "Epoch 12/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2620 - val_loss: 0.2648\n",
            "Epoch 13/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2623 - val_loss: 0.2646\n",
            "Epoch 14/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2653 - val_loss: 0.2647\n",
            "Epoch 15/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2596 - val_loss: 0.2642\n",
            "Epoch 16/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2632 - val_loss: 0.2641\n",
            "Epoch 17/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2650 - val_loss: 0.2640\n",
            "Epoch 18/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2628 - val_loss: 0.2639\n",
            "Epoch 19/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2606 - val_loss: 0.2637\n",
            "Epoch 20/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2623 - val_loss: 0.2636\n",
            "Success! Model trained and saved.\n",
            "Files created: amanpay_model.keras, scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INPUT_FILE = \"amanpay_cleaned.csv\"\n",
        "MODEL_FILE = \"amanpay_model.keras\"  # The saved \"Brain\"\n",
        "SCALER_FILE = \"scaler.pkl\"          # The saved \"Translator\"\n",
        "\n",
        "# 1. Load the Data\n",
        "print(\"Loading data...\")\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "# We only care about these columns for the AI\n",
        "features = ['amount', 'hour', 'lat', 'lon']\n",
        "data = df[features]\n",
        "\n",
        "# 2. Preprocess (Scale the numbers)\n",
        "# AI works better when numbers are small (between 0 and 1)\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# 3. Split Data\n",
        "# We train ONLY on Normal data (is_fraud = 0)\n",
        "# This is called \"Anomaly Detection\"\n",
        "normal_data = data_scaled[df['is_fraud'] == 0]\n",
        "train_data, test_data = train_test_split(normal_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training on {len(train_data)} normal transactions...\")\n",
        "\n",
        "# 4. Build the TensorFlow Model (Autoencoder)\n",
        "# It tries to compress the data and then recreate it.\n",
        "# If it fails to recreate a transaction, that transaction is a SCAM.\n",
        "input_dim = data_scaled.shape[1] # 4 features\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # Encoder (Compress)\n",
        "  layers.Dense(8, activation=\"relu\", input_shape=(input_dim,)),\n",
        "  layers.Dense(4, activation=\"relu\"),\n",
        "\n",
        "  # Decoder (Expand)\n",
        "  layers.Dense(8, activation=\"relu\"),\n",
        "  layers.Dense(input_dim, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# 5. Train the Model\n",
        "history = model.fit(train_data, train_data,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(test_data, test_data),\n",
        "                    shuffle=True,\n",
        "                    verbose=1)\n",
        "\n",
        "# 6. Save the Brain and Scaler\n",
        "model.save(MODEL_FILE)\n",
        "with open(SCALER_FILE, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"Success! Model trained and saved.\")\n",
        "print(f\"Files created: {MODEL_FILE}, {SCALER_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHyFXn7CHI1b",
        "outputId": "7c0f43a3-b97d-412a-fc44-bf77fdf46857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.54.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.6)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (26.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG_hXlLCHPLx",
        "outputId": "a92a492e-4d3e-43d9-dbd5-ef7628d8f490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import db\n",
        "import time\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = \"amanpay_model.keras\"\n",
        "SCALER_FILE = \"scaler.pkl\"\n",
        "FIREBASE_KEY = \"key.json\"  # Ensure you uploaded this file!\n",
        "\n",
        "# PASTE YOUR GOOGLE GEMINI API KEY HERE\n",
        "GOOG_API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "# --- 2. SETUP FIREBASE ---\n",
        "# We use a \"Try/Except\" block to prevent errors when Streamlit reloads\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(FIREBASE_KEY)\n",
        "        firebase_admin.initialize_app(cred, {\n",
        "            'databaseURL': 'OWN_FIREBASE_LINK'\n",
        "            # ^^^ IMPORTANT: REPLACE THIS URL WITH YOUR OWN FIREBASE URL IF IT FAILS ^^^\n",
        "        })\n",
        "        st.toast(\"ğŸ”¥ Firebase Connected!\", icon=\"â˜ï¸\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Firebase not connected: {e}\")\n",
        "\n",
        "# --- 3. AUTO-DETECT GEMINI MODEL ---\n",
        "gemini_active = False\n",
        "model_gemini = None\n",
        "try:\n",
        "    if GOOG_API_KEY.startswith(\"AIza\"):\n",
        "        genai.configure(api_key=GOOG_API_KEY)\n",
        "        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        chosen_model = next((m for m in available_models if \"gemini\" in m), available_models[0] if available_models else None)\n",
        "        if chosen_model:\n",
        "            model_gemini = genai.GenerativeModel(chosen_model)\n",
        "            gemini_active = True\n",
        "except:\n",
        "    gemini_active = False\n",
        "\n",
        "# --- 4. LOAD BRAIN ---\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    if not os.path.exists(MODEL_FILE): return None, None\n",
        "    model = tf.keras.models.load_model(MODEL_FILE)\n",
        "    with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
        "    return model, scaler\n",
        "\n",
        "try:\n",
        "    model, scaler = load_resources()\n",
        "    if model is None: st.stop()\n",
        "except: st.stop()\n",
        "\n",
        "# --- 5. UI LAYOUT ---\n",
        "st.set_page_config(page_title=\"AmanPay AI\", page_icon=\"ğŸ›¡ï¸\", layout=\"wide\")\n",
        "st.title(\"ğŸ›¡ï¸ AmanPay AI\")\n",
        "st.markdown(\"### Securing the Digital Economy for Malaysiaâ€™s Underserved\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- 6. SIDEBAR INPUTS ---\n",
        "st.sidebar.header(\"ğŸ“ Transaction Simulator\")\n",
        "amount = st.sidebar.number_input(\"Amount (RM)\", min_value=1.0, value=20.0, step=10.0)\n",
        "hour = st.sidebar.slider(\"Time of Day (24h)\", 0, 23, 14)\n",
        "st.sidebar.subheader(\"ğŸ“ Location Details\")\n",
        "lat = st.sidebar.number_input(\"Latitude\", value=3.1408, format=\"%.4f\")\n",
        "lon = st.sidebar.number_input(\"Longitude\", value=101.6932, format=\"%.4f\")\n",
        "btn = st.sidebar.button(\"ğŸš€ Analyze Transaction\", type=\"primary\")\n",
        "\n",
        "# --- 7. MAIN LOGIC ---\n",
        "if btn:\n",
        "    # Scale & Predict\n",
        "    input_data = pd.DataFrame([[amount, hour, lat, lon]], columns=['amount', 'hour', 'lat', 'lon'])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    reconstructed = model.predict(input_scaled)\n",
        "    error_score = np.mean(np.power(input_scaled - reconstructed, 2), axis=1)[0]\n",
        "    is_fraud = error_score > 0.5\n",
        "\n",
        "    # === FIREBASE LOGGING ===\n",
        "    # This sends the data to the cloud instantly\n",
        "    try:\n",
        "        ref = db.reference(\"/transactions\")\n",
        "        ref.push({\n",
        "            \"amount\": amount,\n",
        "            \"hour\": hour,\n",
        "            \"risk_score\": float(error_score),\n",
        "            \"status\": \"FRAUD\" if is_fraud else \"SAFE\",\n",
        "            \"timestamp\": time.time()\n",
        "        })\n",
        "        st.toast(\"Data synced to Cloud Database\", icon=\"âœ…\")\n",
        "    except Exception as e:\n",
        "        print(f\"Firebase Error: {e}\")\n",
        "\n",
        "    # === DISPLAY RESULTS ===\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    with col1:\n",
        "        st.subheader(\"ğŸ“Š Analysis Result\")\n",
        "        if is_fraud:\n",
        "            st.error(f\"ğŸš¨ FRAUD DETECTED!\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"High Risk\", delta_color=\"inverse\")\n",
        "\n",
        "            st.markdown(\"#### ğŸ¤– AI Guardian Explanation:\")\n",
        "            if gemini_active:\n",
        "                with st.spinner(\"Analyzing context...\"):\n",
        "                    try:\n",
        "                        prompt = f\"You're a friendly Malaysian security bot. Transaction: RM{amount} at {hour}:00, location {lat},{lon}. Risk score {error_score:.2f}. Explain in 1 casual sentence why this is blocked, using Malaysian slang like 'lah', 'lor', 'wei'. Be protective but friendly.\"\n",
        "                        response = model_gemini.generate_content(prompt)\n",
        "                        st.info(response.text)\n",
        "                    except: st.error(\"AI Busy.\")\n",
        "        else:\n",
        "            st.success(f\"âœ… Transaction Approved\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"Safe\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"ğŸŒ Location Tracker\")\n",
        "        st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}))\n",
        "\n",
        "# --- 8. LIVE HISTORY SECTION ---\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"â˜ï¸ Live Cloud Database Records\")\n",
        "try:\n",
        "    # Read the last 5 transactions from Firebase\n",
        "    ref = db.reference(\"/transactions\")\n",
        "    snapshot = ref.order_by_key().limit_to_last(5).get()\n",
        "\n",
        "    if snapshot:\n",
        "        # Convert Firebase JSON to a nice Table\n",
        "        data_list = []\n",
        "        for key, val in snapshot.items():\n",
        "            data_list.append(val)\n",
        "        df_history = pd.DataFrame(data_list)\n",
        "        # Reorder columns for neatness\n",
        "        st.dataframe(df_history[['status', 'amount', 'risk_score', 'hour']], use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No records in cloud yet.\")\n",
        "except:\n",
        "    st.write(\"Connect Firebase to see history.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG_B8Yu2HWVa",
        "outputId": "99d3afa3-8de7-49d1-d974-6dfb4ea2bbdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import db\n",
        "import time\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = \"amanpay_model.keras\"\n",
        "SCALER_FILE = \"scaler.pkl\"\n",
        "FIREBASE_KEY = \"key.json\"  # Ensure you uploaded this file!\n",
        "\n",
        "# !!! PASTE YOUR GOOGLE GEMINI API KEY HERE !!!\n",
        "GOOG_API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "# --- 2. SETUP FIREBASE ---\n",
        "# We use a \"Try/Except\" block to prevent errors when Streamlit reloads\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(FIREBASE_KEY)\n",
        "        firebase_admin.initialize_app(cred, {\n",
        "            'databaseURL': 'YOUR_DATABASE_LINK'\n",
        "            # ^^^ IMPORTANT: REPLACE THIS URL WITH YOUR OWN FIREBASE URL IF IT FAILS ^^^\n",
        "        })\n",
        "        st.toast(\"ğŸ”¥ Firebase Connected!\", icon=\"â˜ï¸\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Firebase not connected: {e}\")\n",
        "\n",
        "# --- 3. AUTO-DETECT GEMINI MODEL ---\n",
        "gemini_active = False\n",
        "model_gemini = None\n",
        "try:\n",
        "    if GOOG_API_KEY.startswith(\"AIza\"):\n",
        "        genai.configure(api_key=GOOG_API_KEY)\n",
        "        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        chosen_model = next((m for m in available_models if \"gemini\" in m), available_models[0] if available_models else None)\n",
        "        if chosen_model:\n",
        "            model_gemini = genai.GenerativeModel(chosen_model)\n",
        "            gemini_active = True\n",
        "except:\n",
        "    gemini_active = False\n",
        "\n",
        "# --- 4. LOAD BRAIN ---\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    if not os.path.exists(MODEL_FILE): return None, None\n",
        "    model = tf.keras.models.load_model(MODEL_FILE)\n",
        "    with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
        "    return model, scaler\n",
        "\n",
        "try:\n",
        "    model, scaler = load_resources()\n",
        "    if model is None: st.stop()\n",
        "except: st.stop()\n",
        "\n",
        "# --- 5. UI LAYOUT ---\n",
        "st.set_page_config(page_title=\"AmanPay AI\", page_icon=\"ğŸ›¡ï¸\", layout=\"wide\")\n",
        "st.title(\"ğŸ›¡ï¸ AmanPay AI\")\n",
        "st.markdown(\"### Securing the Digital Economy for Malaysiaâ€™s Underserved\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- 6. SIDEBAR INPUTS ---\n",
        "st.sidebar.header(\"ğŸ“ Transaction Simulator\")\n",
        "amount = st.sidebar.number_input(\"Amount (RM)\", min_value=1.0, value=20.0, step=10.0)\n",
        "hour = st.sidebar.slider(\"Time of Day (24h)\", 0, 23, 14)\n",
        "st.sidebar.subheader(\"ğŸ“ Location Details\")\n",
        "lat = st.sidebar.number_input(\"Latitude\", value=3.1408, format=\"%.4f\")\n",
        "lon = st.sidebar.number_input(\"Longitude\", value=101.6932, format=\"%.4f\")\n",
        "btn = st.sidebar.button(\"ğŸš€ Analyze Transaction\", type=\"primary\")\n",
        "\n",
        "# --- 7. MAIN LOGIC ---\n",
        "if btn:\n",
        "    # Scale & Predict\n",
        "    input_data = pd.DataFrame([[amount, hour, lat, lon]], columns=['amount', 'hour', 'lat', 'lon'])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    reconstructed = model.predict(input_scaled)\n",
        "    error_score = np.mean(np.power(input_scaled - reconstructed, 2), axis=1)[0]\n",
        "    is_fraud = error_score > 0.5\n",
        "\n",
        "    # === FIREBASE LOGGING ===\n",
        "    # This sends the data to the cloud instantly\n",
        "    try:\n",
        "        ref = db.reference(\"/transactions\")\n",
        "        ref.push({\n",
        "            \"amount\": amount,\n",
        "            \"hour\": hour,\n",
        "            \"risk_score\": float(error_score),\n",
        "            \"status\": \"FRAUD\" if is_fraud else \"SAFE\",\n",
        "            \"timestamp\": time.time()\n",
        "        })\n",
        "        st.toast(\"Data synced to Cloud Database\", icon=\"âœ…\")\n",
        "    except Exception as e:\n",
        "        print(f\"Firebase Error: {e}\")\n",
        "\n",
        "    # === DISPLAY RESULTS ===\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    with col1:\n",
        "        st.subheader(\"ğŸ“Š Analysis Result\")\n",
        "        if is_fraud:\n",
        "            st.error(f\"ğŸš¨ FRAUD DETECTED!\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"High Risk\", delta_color=\"inverse\")\n",
        "\n",
        "            st.markdown(\"#### ğŸ¤– AI Guardian Explanation:\")\n",
        "            if gemini_active:\n",
        "                with st.spinner(\"Analyzing context...\"):\n",
        "                    try:\n",
        "                        prompt = f\"Act as a security bot. A user spent RM {amount} at hour {hour}. Location: {lat}, {lon}. Risk Score: {error_score:.2f}. Explain professionally in English why this is blocked in 1 sentence.\"\n",
        "                        response = model_gemini.generate_content(prompt)\n",
        "                        st.info(response.text)\n",
        "                    except: st.error(\"AI Busy.\")\n",
        "        else:\n",
        "            st.success(f\"âœ… Transaction Approved\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"Safe\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"ğŸŒ Location Tracker\")\n",
        "        st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}))\n",
        "\n",
        "# --- 8. LIVE HISTORY SECTION ---\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"â˜ï¸ Live Cloud Database Records\")\n",
        "try:\n",
        "    # Read the last 5 transactions from Firebase\n",
        "    ref = db.reference(\"/transactions\")\n",
        "    snapshot = ref.order_by_key().limit_to_last(5).get()\n",
        "\n",
        "    if snapshot:\n",
        "        # Convert Firebase JSON to a nice Table\n",
        "        data_list = []\n",
        "        for key, val in snapshot.items():\n",
        "            data_list.append(val)\n",
        "        df_history = pd.DataFrame(data_list)\n",
        "        # Reorder columns for neatness\n",
        "        st.dataframe(df_history[['status', 'amount', 'risk_score', 'hour']], use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No records in cloud yet.\")\n",
        "except:\n",
        "    st.write(\"Connect Firebase to see history.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UIHfAJxJys4",
        "outputId": "b1bca380-51f6-44b8-a961-3ffc863d7f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2026-02-06 04:20:37--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2026.1.2/cloudflared-linux-amd64 [following]\n",
            "--2026-02-06 04:20:37--  https://github.com/cloudflare/cloudflared/releases/download/2026.1.2/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/106867604/31ade8d6-2fcd-4925-9218-5534d27a01dc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-02-06T05%3A02%3A15Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-02-06T04%3A01%3A40Z&ske=2026-02-06T05%3A02%3A15Z&sks=b&skv=2018-11-09&sig=urOdQEb8ClkEv6hoqnnmIpXxyrvrhgjhb6TzZGRwze0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc3MDM1MzQxNCwibmJmIjoxNzcwMzUxNjE0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.btCuW8NNvnemQc3TRr7exMUzPCTsC5eWzJqrDFbnkMI&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2026-02-06 04:20:37--  https://release-assets.githubusercontent.com/github-production-release-asset/106867604/31ade8d6-2fcd-4925-9218-5534d27a01dc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-02-06T05%3A02%3A15Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-02-06T04%3A01%3A40Z&ske=2026-02-06T05%3A02%3A15Z&sks=b&skv=2018-11-09&sig=urOdQEb8ClkEv6hoqnnmIpXxyrvrhgjhb6TzZGRwze0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc3MDM1MzQxNCwibmJmIjoxNzcwMzUxNjE0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.btCuW8NNvnemQc3TRr7exMUzPCTsC5eWzJqrDFbnkMI&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41260428 (39M) [application/octet-stream]\n",
            "Saving to: â€˜cloudflared-linux-amd64â€™\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  39.35M   135MB/s    in 0.3s    \n",
            "\n",
            "2026-02-06 04:20:38 (135 MB/s) - â€˜cloudflared-linux-amd64â€™ saved [41260428/41260428]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQX6d6NHJ54S",
        "outputId": "09f1e554-5ec2-49cc-f1ed-7fce8d6235ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2026-02-06T04:20:42Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2026-02-06T04:20:42Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m |  https://clinics-added-region-britannica.trycloudflare.com                                 |\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Version 2026.1.2 (Checksum e157c54e929cc289cbd53860453168c2fe3439eb55e2e965a56579252585d9c1)\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.11, GoArch: amd64\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 144bf280-fd26-4779-8430-8995dc248a0a\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "2026/02/06 04:20:46 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2026-02-06T04:20:46Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m6a44c31f-c61d-4fe2-a774-f6b484e32d51 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113 \u001b[36mlocation=\u001b[0mord11 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://136.112.190.167:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2026-02-06 04:21:06.767021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770351666.806070   18586 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770351666.818483   18586 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770351666.848654   18586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770351666.848736   18586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770351666.848742   18586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770351666.848746   18586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/content/app.py:6: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  import google.generativeai as genai\n",
            "2026-02-06 04:21:15.252306: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2026-02-06 04:21:15.897 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n"
          ]
        }
      ],
      "source": [
        "!pkill streamlit\n",
        "!streamlit run app.py & ./cloudflared tunnel --url http://localhost:8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACDN6Zy1w9Gq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvbHzDh_wvT7",
        "outputId": "37b16d1d-b12c-4954-f9f2-a5969d991ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: amanpay_transactions.csv (deflated 71%)\n",
            "  adding: amanpay_model.keras (deflated 86%)\n",
            "  adding: cloudflared (deflated 51%)\n",
            "  adding: key.json (deflated 30%)\n",
            "  adding: app.py (deflated 54%)\n",
            "  adding: scaler.pkl (deflated 28%)\n",
            "  adding: amanpay_cleaned.csv (deflated 71%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r my_project.zip . -x \"sample_data/*\" \".config/*\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
