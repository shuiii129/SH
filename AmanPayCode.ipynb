{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2NdHcVExggJzwVqMa54ft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuiii129/SH/blob/main/AmanPayCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vZVJziVF4LT",
        "outputId": "45c80ad0-a27d-4cf3-e285-e0a326260134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data... please wait.\n",
            "âœ… Success! Generated 5100 transactions in 'amanpay_transactions.csv'.\n",
            "Check your folder, the file should be there.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "NUM_NORMAL = 5000\n",
        "NUM_FRAUD = 100  # These are the \"Hidden\" scams\n",
        "OUTPUT_FILE = \"amanpay_transactions.csv\"\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def generate_normal_transaction():\n",
        "    \"\"\"Simulates a student buying food/transport in Kampar/KL\"\"\"\n",
        "    categories = ['Food', 'Transport', 'Telco', 'Grocery', 'Entertainment']\n",
        "\n",
        "    # Students spend small amounts (RM 5 to RM 50)\n",
        "    amount = round(np.random.normal(20, 10), 2)\n",
        "    if amount < 2: amount = 5.00 # Minimum spend\n",
        "\n",
        "    # Normal hours (8 AM to 11 PM)\n",
        "    hour = random.randint(8, 23)\n",
        "\n",
        "    # Local Coordinates (Kampar/KL area)\n",
        "    # Kampar Lat: 4.3 approx, KL Lat: 3.1 approx\n",
        "    lat = round(random.uniform(3.1, 4.5), 4)\n",
        "    lon = round(random.uniform(101.0, 101.8), 4)\n",
        "\n",
        "    return {\n",
        "        \"amount\": amount,\n",
        "        \"hour\": hour,\n",
        "        \"category\": random.choice(categories),\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"is_fraud\": 0  # 0 means Safe\n",
        "    }\n",
        "\n",
        "def generate_fraud_transaction():\n",
        "    \"\"\"Simulates a scammer draining the account\"\"\"\n",
        "    # Scammers steal BIG amounts or oddly specific amounts\n",
        "    scam_type = random.choice(['DRAIN', 'PHISHING'])\n",
        "\n",
        "    if scam_type == 'DRAIN':\n",
        "        amount = round(random.uniform(2000, 5000), 2)\n",
        "    else:\n",
        "        amount = 199.00 # Phishing often uses repeated exact numbers\n",
        "\n",
        "    # Weird hours (2 AM to 5 AM)\n",
        "    hour = random.randint(0, 5)\n",
        "\n",
        "    # Suspicious Coordinates (Overseas or far away)\n",
        "    # e.g., Macau, Nigeria, or just far North\n",
        "    lat = round(random.uniform(10.0, 50.0), 4)\n",
        "    lon = round(random.uniform(110.0, 120.0), 4)\n",
        "\n",
        "    return {\n",
        "        \"amount\": amount,\n",
        "        \"hour\": hour,\n",
        "        \"category\": \"Transfer\",\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"is_fraud\": 1  # 1 means Fraud\n",
        "    }\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "print(\"Generating data... please wait.\")\n",
        "\n",
        "data = []\n",
        "\n",
        "# 1. Create Normal Data\n",
        "for _ in range(NUM_NORMAL):\n",
        "    data.append(generate_normal_transaction())\n",
        "\n",
        "# 2. Inject Fraud Data\n",
        "for _ in range(NUM_FRAUD):\n",
        "    data.append(generate_fraud_transaction())\n",
        "\n",
        "# 3. Save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Shuffle the data so scams are mixed in\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"âœ… Success! Generated {len(df)} transactions in '{OUTPUT_FILE}'.\")\n",
        "print(\"Check your folder, the file should be there.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "baeZyia0GEhr",
        "outputId": "778ca681-58e2-434e-9928-9e584f51712b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      amount  hour       category     lat       lon  is_fraud\n",
              "0      11.47    12           Food  4.3064  101.4022         0\n",
              "1      21.73    17      Transport  3.1940  101.3076         0\n",
              "2      12.26     9  Entertainment  3.7030  101.0545         0\n",
              "3       3.66    16  Entertainment  3.2773  101.7373         0\n",
              "4       8.47    16          Telco  3.2711  101.4534         0\n",
              "...      ...   ...            ...     ...       ...       ...\n",
              "5095   28.73    17        Grocery  4.4916  101.0657         0\n",
              "5096   22.14    15      Transport  3.3826  101.1601         0\n",
              "5097   15.88    12           Food  4.1569  101.3080         0\n",
              "5098   19.77    22      Transport  4.1804  101.1618         0\n",
              "5099   32.87    21        Grocery  4.1598  101.5163         0\n",
              "\n",
              "[5100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eea01e9-abdc-4e61-af68-129e01aa595a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>hour</th>\n",
              "      <th>category</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>is_fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.47</td>\n",
              "      <td>12</td>\n",
              "      <td>Food</td>\n",
              "      <td>4.3064</td>\n",
              "      <td>101.4022</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.73</td>\n",
              "      <td>17</td>\n",
              "      <td>Transport</td>\n",
              "      <td>3.1940</td>\n",
              "      <td>101.3076</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.26</td>\n",
              "      <td>9</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>3.7030</td>\n",
              "      <td>101.0545</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.66</td>\n",
              "      <td>16</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>3.2773</td>\n",
              "      <td>101.7373</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.47</td>\n",
              "      <td>16</td>\n",
              "      <td>Telco</td>\n",
              "      <td>3.2711</td>\n",
              "      <td>101.4534</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>28.73</td>\n",
              "      <td>17</td>\n",
              "      <td>Grocery</td>\n",
              "      <td>4.4916</td>\n",
              "      <td>101.0657</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>22.14</td>\n",
              "      <td>15</td>\n",
              "      <td>Transport</td>\n",
              "      <td>3.3826</td>\n",
              "      <td>101.1601</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>15.88</td>\n",
              "      <td>12</td>\n",
              "      <td>Food</td>\n",
              "      <td>4.1569</td>\n",
              "      <td>101.3080</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>19.77</td>\n",
              "      <td>22</td>\n",
              "      <td>Transport</td>\n",
              "      <td>4.1804</td>\n",
              "      <td>101.1618</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>32.87</td>\n",
              "      <td>21</td>\n",
              "      <td>Grocery</td>\n",
              "      <td>4.1598</td>\n",
              "      <td>101.5163</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eea01e9-abdc-4e61-af68-129e01aa595a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8eea01e9-abdc-4e61-af68-129e01aa595a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8eea01e9-abdc-4e61-af68-129e01aa595a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_d472df78-a2d8-4202-9f67-e542596b8195\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d472df78-a2d8-4202-9f67-e542596b8195 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5100,\n  \"fields\": [\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 315.9555633370377,\n        \"min\": 2.02,\n        \"max\": 4854.84,\n        \"num_unique_values\": 2682,\n        \"samples\": [\n          29.67,\n          34.54,\n          10.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          12,\n          11,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Food\",\n          \"Transport\",\n          \"Transfer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8649340930596288,\n        \"min\": 3.1001,\n        \"max\": 49.8784,\n        \"num_unique_values\": 4323,\n        \"samples\": [\n          3.6768,\n          3.8229,\n          3.683\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9894889042695247,\n        \"min\": 101.0,\n        \"max\": 119.9863,\n        \"num_unique_values\": 3783,\n        \"samples\": [\n          101.7307,\n          101.1844,\n          101.6763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_fraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INPUT_FILE = \"amanpay_transactions.csv\"\n",
        "OUTPUT_FILE = \"amanpay_cleaned.csv\"\n",
        "\n",
        "def clean_data():\n",
        "    print(\"ğŸ§¹ Starting Data Cleaning Process...\")\n",
        "\n",
        "    # 1. Load the Data\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_FILE)\n",
        "        print(f\"   -> Loaded {len(df)} rows.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ Error: generate_data.py hasn't been run yet!\")\n",
        "        return\n",
        "\n",
        "    # 2. Check for Missing Values (and remove them)\n",
        "    if df.isnull().sum().sum() > 0:\n",
        "        print(f\"   -> Found missing values. Removing...\")\n",
        "        df = df.dropna()\n",
        "    else:\n",
        "        print(\"   -> No missing values found. (Good!)\")\n",
        "\n",
        "    # 3. Remove Duplicates\n",
        "    # In real banking, duplicates might happen due to system glitches\n",
        "    initial_count = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    final_count = len(df)\n",
        "\n",
        "    if initial_count > final_count:\n",
        "        print(f\"   -> Removed {initial_count - final_count} duplicate rows.\")\n",
        "    else:\n",
        "        print(\"   -> No duplicates found.\")\n",
        "\n",
        "    # 4. Data Type Conversion (Optimization)\n",
        "    # Ensure 'amount' is a number (float)\n",
        "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
        "\n",
        "    # 5. Save the Cleaned Data\n",
        "    df.to_csv(OUTPUT_FILE, index=False)\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(f\"Data Cleaning Complete!\")\n",
        "    print(f\"   -> Saved cleaned data to: '{OUTPUT_FILE}'\")\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "    # Show a quick summary for the User\n",
        "    print(\"\\nData Preview (First 5 rows):\")\n",
        "    print(df.head())\n",
        "    print(\"\\nStatistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clean_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad-OkheGHfF",
        "outputId": "38200d30-0b25-4254-ef9c-02d790cb9870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ Starting Data Cleaning Process...\n",
            "   -> Loaded 5100 rows.\n",
            "   -> No missing values found. (Good!)\n",
            "   -> No duplicates found.\n",
            "------------------------------------------------\n",
            "Data Cleaning Complete!\n",
            "   -> Saved cleaned data to: 'amanpay_cleaned.csv'\n",
            "------------------------------------------------\n",
            "\n",
            "Data Preview (First 5 rows):\n",
            "   amount  hour       category     lat       lon  is_fraud\n",
            "0   11.47    12           Food  4.3064  101.4022         0\n",
            "1   21.73    17      Transport  3.1940  101.3076         0\n",
            "2   12.26     9  Entertainment  3.7030  101.0545         0\n",
            "3    3.66    16  Entertainment  3.2773  101.7373         0\n",
            "4    8.47    16          Telco  3.2711  101.4534         0\n",
            "\n",
            "Statistics:\n",
            "            amount         hour          lat          lon     is_fraud\n",
            "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000\n",
            "mean     50.508794    15.183137     4.297101   101.673192     0.019608\n",
            "std     315.955563     4.923517     3.864934     1.989489     0.138662\n",
            "min       2.020000     0.000000     3.100100   101.000000     0.000000\n",
            "25%      13.230000    11.000000     3.458200   101.199725     0.000000\n",
            "50%      20.085000    15.000000     3.825750   101.408050     0.000000\n",
            "75%      27.030000    19.000000     4.172225   101.609100     0.000000\n",
            "max    4854.840000    23.000000    49.878400   119.986300     1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INPUT_FILE = \"amanpay_cleaned.csv\"\n",
        "MODEL_FILE = \"amanpay_model.keras\"  # The saved \"Brain\"\n",
        "SCALER_FILE = \"scaler.pkl\"          # The saved \"Translator\"\n",
        "\n",
        "# 1. Load the Data\n",
        "print(\"Loading data...\")\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "# We only care about these columns for the AI\n",
        "features = ['amount', 'hour', 'lat', 'lon']\n",
        "data = df[features]\n",
        "\n",
        "# 2. Preprocess (Scale the numbers)\n",
        "# AI works better when numbers are small (between 0 and 1)\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# 3. Split Data\n",
        "# We train ONLY on Normal data (is_fraud = 0)\n",
        "# This is called \"Anomaly Detection\"\n",
        "normal_data = data_scaled[df['is_fraud'] == 0]\n",
        "train_data, test_data = train_test_split(normal_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training on {len(train_data)} normal transactions...\")\n",
        "\n",
        "# 4. Build the TensorFlow Model (Autoencoder)\n",
        "# It tries to compress the data and then recreate it.\n",
        "# If it fails to recreate a transaction, that transaction is a SCAM.\n",
        "input_dim = data_scaled.shape[1] # 4 features\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # Encoder (Compress)\n",
        "  layers.Dense(8, activation=\"relu\", input_shape=(input_dim,)),\n",
        "  layers.Dense(4, activation=\"relu\"),\n",
        "\n",
        "  # Decoder (Expand)\n",
        "  layers.Dense(8, activation=\"relu\"),\n",
        "  layers.Dense(input_dim, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# 5. Train the Model\n",
        "history = model.fit(train_data, train_data,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(test_data, test_data),\n",
        "                    shuffle=True,\n",
        "                    verbose=1)\n",
        "\n",
        "# 6. Save the Brain and Scaler\n",
        "model.save(MODEL_FILE)\n",
        "with open(SCALER_FILE, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"Success! Model trained and saved.\")\n",
        "print(f\"Files created: {MODEL_FILE}, {SCALER_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8cOLnn3GOvj",
        "outputId": "96fb746a-e0d6-44cb-c572-b3742fc5c660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Training on 4000 normal transactions...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6721 - val_loss: 0.5656\n",
            "Epoch 2/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4921 - val_loss: 0.3365\n",
            "Epoch 3/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3070 - val_loss: 0.2440\n",
            "Epoch 4/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2336 - val_loss: 0.2219\n",
            "Epoch 5/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2193 - val_loss: 0.2181\n",
            "Epoch 6/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2143 - val_loss: 0.2164\n",
            "Epoch 7/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2144 - val_loss: 0.2151\n",
            "Epoch 8/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2150 - val_loss: 0.2145\n",
            "Epoch 9/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2117 - val_loss: 0.2140\n",
            "Epoch 10/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2126 - val_loss: 0.2139\n",
            "Epoch 11/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2112 - val_loss: 0.2136\n",
            "Epoch 12/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2105 - val_loss: 0.2136\n",
            "Epoch 13/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2129 - val_loss: 0.2136\n",
            "Epoch 14/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2156 - val_loss: 0.2134\n",
            "Epoch 15/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2111 - val_loss: 0.2133\n",
            "Epoch 16/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2111 - val_loss: 0.2132\n",
            "Epoch 17/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2137 - val_loss: 0.2132\n",
            "Epoch 18/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2149 - val_loss: 0.2131\n",
            "Epoch 19/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2112 - val_loss: 0.2128\n",
            "Epoch 20/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2102 - val_loss: 0.2126\n",
            "Success! Model trained and saved.\n",
            "Files created: amanpay_model.keras, scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHyFXn7CHI1b",
        "outputId": "8ac2498d-716e-4ecf-ceb9-8cfe8252b861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.53.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.53.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.53.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import db\n",
        "import time\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = \"amanpay_model.keras\"\n",
        "SCALER_FILE = \"scaler.pkl\"\n",
        "FIREBASE_KEY = \"key.json\"  # Ensure you uploaded this file!\n",
        "\n",
      
        "GOOG_API_KEY = "PUT_YOUR_API_KEY",
        "\n",
        "# --- 2. SETUP FIREBASE ---\n",
        "# We use a \"Try/Except\" block to prevent errors when Streamlit reloads\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(FIREBASE_KEY)\n",
        "        firebase_admin.initialize_app(cred, {\n",
        "            'databaseURL': 'https://amanpay-db-default-rtdb.asia-southeast1.firebasedatabase.app/'\n",
        "            # ^^^ IMPORTANT: REPLACE THIS URL WITH YOUR OWN FIREBASE URL IF IT FAILS ^^^\n",
        "        })\n",
        "        st.toast(\"ğŸ”¥ Firebase Connected!\", icon=\"â˜ï¸\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Firebase not connected: {e}\")\n",
        "\n",
        "# --- 3. AUTO-DETECT GEMINI MODEL ---\n",
        "gemini_active = False\n",
        "model_gemini = None\n",
        "try:\n",
        "    if GOOG_API_KEY.startswith(\"AIza\"):\n",
        "        genai.configure(api_key=GOOG_API_KEY)\n",
        "        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        chosen_model = next((m for m in available_models if \"gemini\" in m), available_models[0] if available_models else None)\n",
        "        if chosen_model:\n",
        "            model_gemini = genai.GenerativeModel(chosen_model)\n",
        "            gemini_active = True\n",
        "except:\n",
        "    gemini_active = False\n",
        "\n",
        "# --- 4. LOAD BRAIN ---\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    if not os.path.exists(MODEL_FILE): return None, None\n",
        "    model = tf.keras.models.load_model(MODEL_FILE)\n",
        "    with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
        "    return model, scaler\n",
        "\n",
        "try:\n",
        "    model, scaler = load_resources()\n",
        "    if model is None: st.stop()\n",
        "except: st.stop()\n",
        "\n",
        "# --- 5. UI LAYOUT ---\n",
        "st.set_page_config(page_title=\"AmanPay AI\", page_icon=\"ğŸ›¡ï¸\", layout=\"wide\")\n",
        "st.title(\"ğŸ›¡ï¸ AmanPay AI\")\n",
        "st.markdown(\"### Securing the Digital Economy for Malaysiaâ€™s Underserved\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- 6. SIDEBAR INPUTS ---\n",
        "st.sidebar.header(\"ğŸ“ Transaction Simulator\")\n",
        "amount = st.sidebar.number_input(\"Amount (RM)\", min_value=1.0, value=20.0, step=10.0)\n",
        "hour = st.sidebar.slider(\"Time of Day (24h)\", 0, 23, 14)\n",
        "st.sidebar.subheader(\"ğŸ“ Location Details\")\n",
        "lat = st.sidebar.number_input(\"Latitude\", value=3.1408, format=\"%.4f\")\n",
        "lon = st.sidebar.number_input(\"Longitude\", value=101.6932, format=\"%.4f\")\n",
        "btn = st.sidebar.button(\"ğŸš€ Analyze Transaction\", type=\"primary\")\n",
        "\n",
        "# --- 7. MAIN LOGIC ---\n",
        "if btn:\n",
        "    # Scale & Predict\n",
        "    input_data = pd.DataFrame([[amount, hour, lat, lon]], columns=['amount', 'hour', 'lat', 'lon'])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    reconstructed = model.predict(input_scaled)\n",
        "    error_score = np.mean(np.power(input_scaled - reconstructed, 2), axis=1)[0]\n",
        "    is_fraud = error_score > 0.5\n",
        "\n",
        "    # === FIREBASE LOGGING ===\n",
        "    # This sends the data to the cloud instantly\n",
        "    try:\n",
        "        ref = db.reference(\"/transactions\")\n",
        "        ref.push({\n",
        "            \"amount\": amount,\n",
        "            \"hour\": hour,\n",
        "            \"risk_score\": float(error_score),\n",
        "            \"status\": \"FRAUD\" if is_fraud else \"SAFE\",\n",
        "            \"timestamp\": time.time()\n",
        "        })\n",
        "        st.toast(\"Data synced to Cloud Database\", icon=\"âœ…\")\n",
        "    except Exception as e:\n",
        "        print(f\"Firebase Error: {e}\")\n",
        "\n",
        "    # === DISPLAY RESULTS ===\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    with col1:\n",
        "        st.subheader(\"ğŸ“Š Analysis Result\")\n",
        "        if is_fraud:\n",
        "            st.error(f\"ğŸš¨ FRAUD DETECTED!\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"High Risk\", delta_color=\"inverse\")\n",
        "\n",
        "            st.markdown(\"#### ğŸ¤– AI Guardian Explanation:\")\n",
        "            if gemini_active:\n",
        "                with st.spinner(\"Analyzing context...\"):\n",
        "                    try:\n",
        "                        prompt = f\"Act as a security bot. A user spent RM {amount} at hour {hour}. Location: {lat}, {lon}. Risk Score: {error_score:.2f}. Explain professionally in English why this is blocked in 1 sentence.\"\n",
        "                        response = model_gemini.generate_content(prompt)\n",
        "                        st.info(response.text)\n",
        "                    except: st.error(\"AI Busy.\")\n",
        "        else:\n",
        "            st.success(f\"âœ… Transaction Approved\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"Safe\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"ğŸŒ Location Tracker\")\n",
        "        st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}))\n",
        "\n",
        "# --- 8. LIVE HISTORY SECTION ---\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"â˜ï¸ Live Cloud Database Records\")\n",
        "try:\n",
        "    # Read the last 5 transactions from Firebase\n",
        "    ref = db.reference(\"/transactions\")\n",
        "    snapshot = ref.order_by_key().limit_to_last(5).get()\n",
        "\n",
        "    if snapshot:\n",
        "        # Convert Firebase JSON to a nice Table\n",
        "        data_list = []\n",
        "        for key, val in snapshot.items():\n",
        "            data_list.append(val)\n",
        "        df_history = pd.DataFrame(data_list)\n",
        "        # Reorder columns for neatness\n",
        "        st.dataframe(df_history[['status', 'amount', 'risk_score', 'hour']], use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No records in cloud yet.\")\n",
        "except:\n",
        "    st.write(\"Connect Firebase to see history.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG_hXlLCHPLx",
        "outputId": "a5dea548-940f-4b6b-a6aa-57004f0a1dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import db\n",
        "import time\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = \"amanpay_model.keras\"\n",
        "SCALER_FILE = \"scaler.pkl\"\n",
        "FIREBASE_KEY = \"key.json\"  # Ensure you uploaded this file!\n",
        "\n",
        "# !!! PASTE YOUR GOOGLE GEMINI API KEY HERE !!!\n",
        "GOOG_API_KEY = \"AIzaSyA4j5xl1lkGEKx3LTTYsTJMCs9q6FNpDkE\"\n",
        "\n",
        "# --- 2. SETUP FIREBASE ---\n",
        "# We use a \"Try/Except\" block to prevent errors when Streamlit reloads\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(FIREBASE_KEY)\n",
        "        firebase_admin.initialize_app(cred, {\n",
        "            'databaseURL': 'https://aipay-61b05-default-rtdb.asia-southeast1.firebasedatabase.app/'\n",
        "            # ^^^ IMPORTANT: REPLACE THIS URL WITH YOUR OWN FIREBASE URL IF IT FAILS ^^^\n",
        "        })\n",
        "        st.toast(\"ğŸ”¥ Firebase Connected!\", icon=\"â˜ï¸\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Firebase not connected: {e}\")\n",
        "\n",
        "# --- 3. AUTO-DETECT GEMINI MODEL ---\n",
        "gemini_active = False\n",
        "model_gemini = None\n",
        "try:\n",
        "    if GOOG_API_KEY.startswith(\"AIza\"):\n",
        "        genai.configure(api_key=GOOG_API_KEY)\n",
        "        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        chosen_model = next((m for m in available_models if \"gemini\" in m), available_models[0] if available_models else None)\n",
        "        if chosen_model:\n",
        "            model_gemini = genai.GenerativeModel(chosen_model)\n",
        "            gemini_active = True\n",
        "except:\n",
        "    gemini_active = False\n",
        "\n",
        "# --- 4. LOAD BRAIN ---\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    if not os.path.exists(MODEL_FILE): return None, None\n",
        "    model = tf.keras.models.load_model(MODEL_FILE)\n",
        "    with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
        "    return model, scaler\n",
        "\n",
        "try:\n",
        "    model, scaler = load_resources()\n",
        "    if model is None: st.stop()\n",
        "except: st.stop()\n",
        "\n",
        "# --- 5. UI LAYOUT ---\n",
        "st.set_page_config(page_title=\"AmanPay AI\", page_icon=\"ğŸ›¡ï¸\", layout=\"wide\")\n",
        "st.title(\"ğŸ›¡ï¸ AmanPay AI\")\n",
        "st.markdown(\"### Securing the Digital Economy for Malaysiaâ€™s Underserved\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- 6. SIDEBAR INPUTS ---\n",
        "st.sidebar.header(\"ğŸ“ Transaction Simulator\")\n",
        "amount = st.sidebar.number_input(\"Amount (RM)\", min_value=1.0, value=20.0, step=10.0)\n",
        "hour = st.sidebar.slider(\"Time of Day (24h)\", 0, 23, 14)\n",
        "st.sidebar.subheader(\"ğŸ“ Location Details\")\n",
        "lat = st.sidebar.number_input(\"Latitude\", value=3.1408, format=\"%.4f\")\n",
        "lon = st.sidebar.number_input(\"Longitude\", value=101.6932, format=\"%.4f\")\n",
        "btn = st.sidebar.button(\"ğŸš€ Analyze Transaction\", type=\"primary\")\n",
        "\n",
        "# --- 7. MAIN LOGIC ---\n",
        "if btn:\n",
        "    # Scale & Predict\n",
        "    input_data = pd.DataFrame([[amount, hour, lat, lon]], columns=['amount', 'hour', 'lat', 'lon'])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    reconstructed = model.predict(input_scaled)\n",
        "    error_score = np.mean(np.power(input_scaled - reconstructed, 2), axis=1)[0]\n",
        "    is_fraud = error_score > 0.5\n",
        "\n",
        "    # === FIREBASE LOGGING ===\n",
        "    # This sends the data to the cloud instantly\n",
        "    try:\n",
        "        ref = db.reference(\"/transactions\")\n",
        "        ref.push({\n",
        "            \"amount\": amount,\n",
        "            \"hour\": hour,\n",
        "            \"risk_score\": float(error_score),\n",
        "            \"status\": \"FRAUD\" if is_fraud else \"SAFE\",\n",
        "            \"timestamp\": time.time()\n",
        "        })\n",
        "        st.toast(\"Data synced to Cloud Database\", icon=\"âœ…\")\n",
        "    except Exception as e:\n",
        "        print(f\"Firebase Error: {e}\")\n",
        "\n",
        "    # === DISPLAY RESULTS ===\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    with col1:\n",
        "        st.subheader(\"ğŸ“Š Analysis Result\")\n",
        "        if is_fraud:\n",
        "            st.error(f\"ğŸš¨ FRAUD DETECTED!\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"High Risk\", delta_color=\"inverse\")\n",
        "\n",
        "            st.markdown(\"#### ğŸ¤– AI Guardian Explanation:\")\n",
        "            if gemini_active:\n",
        "                with st.spinner(\"Analyzing context...\"):\n",
        "                    try:\n",
        "                        prompt = f\"Act as a security bot. A user spent RM {amount} at hour {hour}. Location: {lat}, {lon}. Risk Score: {error_score:.2f}. Explain professionally in English why this is blocked in 1 sentence.\"\n",
        "                        response = model_gemini.generate_content(prompt)\n",
        "                        st.info(response.text)\n",
        "                    except: st.error(\"AI Busy.\")\n",
        "        else:\n",
        "            st.success(f\"âœ… Transaction Approved\")\n",
        "            st.metric(\"Risk Score\", f\"{error_score:.4f}\", \"Safe\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"ğŸŒ Location Tracker\")\n",
        "        st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}))\n",
        "\n",
        "# --- 8. LIVE HISTORY SECTION ---\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"â˜ï¸ Live Cloud Database Records\")\n",
        "try:\n",
        "    # Read the last 5 transactions from Firebase\n",
        "    ref = db.reference(\"/transactions\")\n",
        "    snapshot = ref.order_by_key().limit_to_last(5).get()\n",
        "\n",
        "    if snapshot:\n",
        "        # Convert Firebase JSON to a nice Table\n",
        "        data_list = []\n",
        "        for key, val in snapshot.items():\n",
        "            data_list.append(val)\n",
        "        df_history = pd.DataFrame(data_list)\n",
        "        # Reorder columns for neatness\n",
        "        st.dataframe(df_history[['status', 'amount', 'risk_score', 'hour']], use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No records in cloud yet.\")\n",
        "except:\n",
        "    st.write(\"Connect Firebase to see history.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG_B8Yu2HWVa",
        "outputId": "ba596979-ed50-4f7c-db8e-694b73cd8b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UIHfAJxJys4",
        "outputId": "32d68ede-f22e-4c13-8839-8160c53c46c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-15 14:55:08--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.11.1/cloudflared-linux-amd64 [following]\n",
            "--2026-01-15 14:55:08--  https://github.com/cloudflare/cloudflared/releases/download/2025.11.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/106867604/955e9d1b-ac5e-4188-8867-e5f53958a8fe?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-15T15%3A51%3A07Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-15T14%3A50%3A34Z&ske=2026-01-15T15%3A51%3A07Z&sks=b&skv=2018-11-09&sig=TAfFDd2CPJK1osblHJPMnHR0amZVP7Fo7wD%2FguHcX%2B8%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODQ5MDcwOCwibmJmIjoxNzY4NDg4OTA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.F80VeCh4jeDtboiGzBJcySevCO6bsmkADvbKGCJo2EA&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2026-01-15 14:55:08--  https://release-assets.githubusercontent.com/github-production-release-asset/106867604/955e9d1b-ac5e-4188-8867-e5f53958a8fe?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-15T15%3A51%3A07Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-15T14%3A50%3A34Z&ske=2026-01-15T15%3A51%3A07Z&sks=b&skv=2018-11-09&sig=TAfFDd2CPJK1osblHJPMnHR0amZVP7Fo7wD%2FguHcX%2B8%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODQ5MDcwOCwibmJmIjoxNzY4NDg4OTA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.F80VeCh4jeDtboiGzBJcySevCO6bsmkADvbKGCJo2EA&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41258324 (39M) [application/octet-stream]\n",
            "Saving to: â€˜cloudflared-linux-amd64â€™\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  39.35M   248MB/s    in 0.2s    \n",
            "\n",
            "2026-01-15 14:55:08 (248 MB/s) - â€˜cloudflared-linux-amd64â€™ saved [41258324/41258324]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill streamlit\n",
        "!streamlit run app.py & ./cloudflared tunnel --url http://localhost:8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQX6d6NHJ54S",
        "outputId": "bab521d0-0c70-41ef-f158-f045cab81f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2026-01-15T14:55:49Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2026-01-15T14:55:49Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.48.41.44:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m |  https://filed-pull-formation-version.trycloudflare.com                                    |\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 563f61b1-4356-4d4f-888d-dc74ea57d8b8\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "2026/01/15 14:55:54 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2026-01-15T14:55:54Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m524048c7-34fd-46ce-b695-55d411dc9c65 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113 \u001b[36mlocation=\u001b[0miad12 \u001b[36mprotocol=\u001b[0mquic\n",
            "2026-01-15 14:56:09.622347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768488969.662757    5218 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768488969.675384    5218 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768488969.705906    5218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768488969.705952    5218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768488969.705961    5218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768488969.705970    5218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/content/app.py:6: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  import google.generativeai as genai\n",
            "2026-01-15 14:56:17.547476: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2026-01-15 14:56:18.220 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-15 14:57:12.483 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "2026-01-15 14:57:19.640 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2026-01-15T14:58:33Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    }
  ]
}
